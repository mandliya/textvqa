{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of textvqa (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "textvqa",
      "language": "python",
      "name": "textvqa"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mandliya/textvqa/blob/master/text_vqa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxIl0WAvsGR9",
        "colab_type": "code",
        "outputId": "71e2c477-8815-48a2-f7cc-b55df1970460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "# Install dependencies\n",
        "!pip install ninja yacs cython matplotlib demjson\n",
        "!pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/bf/32e5dd5cce6543374e4050a7292099402ab80787eddf3732810a55b37763/ninja-1.9.0.post1-py3-none-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.7MB/s \n",
            "\u001b[?25hCollecting yacs\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/51/9d613d67a8561a0cdf696c3909870f157ed85617fea3cff769bb7de09ef7/yacs-0.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Collecting demjson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/67/6db789e2533158963d4af689f961b644ddd9200615b8ce92d6cad695c65a/demjson-2.2.4.tar.gz (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs) (3.13)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
            "Building wheels for collected packages: demjson\n",
            "  Building wheel for demjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/d2/ab/a54fb5ea53ac3badba098160e8452fa126a51febda80440ded\n",
            "Successfully built demjson\n",
            "Installing collected packages: ninja, yacs, demjson\n",
            "Successfully installed demjson-2.2.4 ninja-1.9.0.post1 yacs-0.1.6\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-kd5nxhnv\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-kd5nxhnv\n",
            "Requirement already satisfied (use --upgrade to upgrade): pycocotools==2.0 from git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (41.0.1)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.10)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_qx8mg0c/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCQFQObQsGSI",
        "colab_type": "code",
        "outputId": "1ee6488d-acbe-40c1-9022-b253a63292b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf fastText\n",
        "!git clone https://github.com/facebookresearch/fastText.git fastText\n",
        "%cd /content/fastText\n",
        "!pip install -e ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 2, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3197 (delta 0), reused 1 (delta 0), pack-reused 3195\u001b[K\n",
            "Receiving objects: 100% (3197/3197), 7.84 MiB | 33.88 MiB/s, done.\n",
            "Resolving deltas: 100% (2007/2007), done.\n",
            "/content/fastText\n",
            "Obtaining file:///content/fastText\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.8.22) (2.2.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.8.22) (41.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.8.22) (1.16.4)\n",
            "Installing collected packages: fasttext\n",
            "  Running setup.py develop for fasttext\n",
            "Successfully installed fasttext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgbVL6SussJ1",
        "colab_type": "code",
        "outputId": "577387fd-c834-4432-dfb6-45b08006a87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "source": [
        "%cd /content/\n",
        "%rm -rf pythia\n",
        "!git clone https://github.com/facebookresearch/pythia.git pythia\n",
        "%cd /content/pythia\n",
        "# Don't modify torch version\n",
        "!sed -i '/torch/d' requirements.txt\n",
        "!pip install -e .\n",
        "import sys\n",
        "sys.path.append('/content/pythia')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'pythia'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 3295 (delta 16), reused 42 (delta 14), pack-reused 3218\n",
            "Receiving objects: 100% (3295/3295), 6.51 MiB | 20.26 MiB/s, done.\n",
            "Resolving deltas: 100% (2129/2129), done.\n",
            "/content/pythia\n",
            "Obtaining file:///content/pythia\n",
            "Collecting tensorboardX==1.2 (from pythia==0.3)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/22/43f4f0318f7c68a1000dbb700a353b745584bc2397437832d15ba69ea5f1/tensorboardX-1.2-py2.py3-none-any.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pythia==0.3) (1.16.4)\n",
            "Collecting tqdm==4.19.9 (from pythia==0.3)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c4/b67cf1ab472b770e08e94105a0c7ca7032cd070627c435f5998c9cf6e64f/tqdm-4.19.9-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: demjson>=2.2 in /usr/local/lib/python3.6/dist-packages (from pythia==0.3) (2.2.4)\n",
            "Collecting GitPython>=2.1 (from pythia==0.3)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/e5/fafe827507644c32d6dc553a1c435cdf882e0c28918a5bab29f7fbebfb70/GitPython-2.1.11-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from pythia==0.3) (3.13)\n",
            "Collecting pytest==3.3.2 (from pythia==0.3)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/af/8dcf688d192914928393f931b7b550f2530299bbb08018b2f17efa6aab73/pytest-3.3.2-py2.py3-none-any.whl (185kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from pythia==0.3) (2.21.0)\n",
            "Requirement already satisfied: fastText in /content/fastText/python (from pythia==0.3) (0.8.22)\n",
            "Collecting nltk==3.4.1 (from pythia==0.3)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/56/90178929712ce427ebad179f8dc46c8deef4e89d4c853092bee1efd57d05/nltk-3.4.1.zip (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.2->pythia==0.3) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.2->pythia==0.3) (1.12.0)\n",
            "Collecting gitdb2>=2.0.0 (from GitPython>=2.1->pythia==0.3)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 22.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.2.0 in /usr/local/lib/python3.6/dist-packages (from pytest==3.3.2->pythia==0.3) (19.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest==3.3.2->pythia==0.3) (41.0.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest==3.3.2->pythia==0.3) (1.8.0)\n",
            "Collecting pluggy<0.7,>=0.5 (from pytest==3.3.2->pythia==0.3)\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/65/ded3bc40bbf8d887f262f150fbe1ae6637765b5c9534bd55690ed2c0b0f7/pluggy-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->pythia==0.3) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->pythia==0.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->pythia==0.3) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->pythia==0.3) (3.0.4)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fastText->pythia==0.3) (2.2.4)\n",
            "Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=2.1->pythia==0.3)\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/8a/10/d646015f33c525688e91986c4544c68019b19a473cb33d3b55\n",
            "Successfully built nltk\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboardX, tqdm, smmap2, gitdb2, GitPython, pluggy, pytest, nltk, pythia\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Running setup.py develop for pythia\n",
            "Successfully installed GitPython-2.1.11 gitdb2-2.0.5 nltk-3.4.1 pluggy-0.6.0 pytest-3.3.2 pythia smmap2-2.0.5 tensorboardX-1.2 tqdm-4.19.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy9zowwesGSt",
        "colab_type": "code",
        "outputId": "67341860-0bcd-4d51-d959-84994d29ede1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3352
        }
      },
      "source": [
        "# Install maskrcnn-benchmark to extract detectron features\n",
        "%cd /content\n",
        "!git clone https://gitlab.com/meetshah1995/vqa-maskrcnn-benchmark.git\n",
        "%cd /content/vqa-maskrcnn-benchmark\n",
        "# Compile custom layers and build mask-rcnn backbone\n",
        "!python setup.py build\n",
        "!python setup.py develop\n",
        "sys.path.append('/content/vqa-maskrcnn-benchmark')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'vqa-maskrcnn-benchmark'...\n",
            "remote: Enumerating objects: 730, done.\u001b[K\n",
            "remote: Counting objects: 100% (730/730), done.\u001b[K\n",
            "remote: Compressing objects: 100% (337/337), done.\u001b[K\n",
            "remote: Total 730 (delta 402), reused 701 (delta 386)\u001b[K\n",
            "Receiving objects: 100% (730/730), 3.76 MiB | 33.46 MiB/s, done.\n",
            "Resolving deltas: 100% (402/402), done.\n",
            "/content/vqa-maskrcnn-benchmark\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark\n",
            "copying maskrcnn_benchmark/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/bounding_box.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/image_list.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/boxlist_ops.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
            "copying maskrcnn_benchmark/structures/segmentation_mask.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
            "copying maskrcnn_benchmark/data/build.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
            "copying maskrcnn_benchmark/data/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
            "copying maskrcnn_benchmark/data/collate_batch.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
            "copying maskrcnn_benchmark/config/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
            "copying maskrcnn_benchmark/config/paths_catalog.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
            "copying maskrcnn_benchmark/config/defaults.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/comm.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/imports.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/env.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/checkpoint.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/metric_logger.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/logger.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/miscellaneous.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/model_serialization.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/c2_model_loading.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/model_zoo.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/registry.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "copying maskrcnn_benchmark/utils/collect_env.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/matcher.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/poolers.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/box_coder.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/registry.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "copying maskrcnn_benchmark/modeling/utils.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/smooth_l1_loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/_utils.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/nms.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/roi_pool.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/misc.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/batch_norm.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "copying maskrcnn_benchmark/layers/roi_align.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
            "copying maskrcnn_benchmark/solver/build.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
            "copying maskrcnn_benchmark/solver/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
            "copying maskrcnn_benchmark/solver/lr_scheduler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
            "copying maskrcnn_benchmark/engine/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
            "copying maskrcnn_benchmark/engine/trainer.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
            "copying maskrcnn_benchmark/engine/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
            "copying maskrcnn_benchmark/data/samplers/distributed.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/list_dataset.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/concat_dataset.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/coco.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
            "copying maskrcnn_benchmark/data/datasets/voc.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
            "copying maskrcnn_benchmark/data/transforms/build.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
            "copying maskrcnn_benchmark/data/transforms/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
            "copying maskrcnn_benchmark/data/transforms/transforms.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
            "copying maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/rpn.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/anchor_generator.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
            "copying maskrcnn_benchmark/modeling/rpn/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/backbone.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
            "copying maskrcnn_benchmark/modeling/backbone/resnet.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
            "copying maskrcnn_benchmark/modeling/detector/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
            "copying maskrcnn_benchmark/modeling/detector/generalized_rcnn.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
            "copying maskrcnn_benchmark/modeling/detector/detectors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
            "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
            "running build_ext\n",
            "building 'maskrcnn_benchmark._C' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/content\n",
            "creating build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark\n",
            "creating build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark\n",
            "creating build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc\n",
            "creating build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c /content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp -o build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c /content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp -o build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:71:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(TYPE\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                        \\\n",
            "                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c /content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp -o build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:71:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(TYPE\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                        \\\n",
            "                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o build/temp.linux-x86_64-3.6/content/vqa-maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o -o build/lib.linux-x86_64-3.6/maskrcnn_benchmark/_C.cpython-36m-x86_64-linux-gnu.so\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running develop\n",
            "running egg_info\n",
            "creating maskrcnn_benchmark.egg-info\n",
            "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
            "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
            "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
            "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.6/maskrcnn_benchmark/_C.cpython-36m-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
            "Creating /usr/local/lib/python3.6/dist-packages/maskrcnn-benchmark.egg-link (link to .)\n",
            "Adding maskrcnn-benchmark 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/vqa-maskrcnn-benchmark\n",
            "Processing dependencies for maskrcnn-benchmark==0.1\n",
            "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMy0BC7CsGTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import yaml\n",
        "import cv2\n",
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from ipywidgets import widgets, Layout\n",
        "from io import BytesIO\n",
        "\n",
        "from maskrcnn_benchmark.config import cfg\n",
        "from maskrcnn_benchmark.layers import nms\n",
        "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
        "from maskrcnn_benchmark.structures.image_list import to_image_list\n",
        "from maskrcnn_benchmark.utils.model_serialization import load_state_dict\n",
        "\n",
        "from pythia.utils.configuration import ConfigNode\n",
        "from pythia.tasks.processors import VocabProcessor, VQAAnswerProcessor\n",
        "from pythia.tasks.processors import FastTextProcessor, SoftCopyAnswerProcessor, SimpleWordProcessor\n",
        "from pythia.models import LoRRA\n",
        "from pythia.common.registry import registry\n",
        "from pythia.common.sample import Sample, SampleList\n",
        "from pprint import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft982JRksGTP",
        "colab_type": "code",
        "outputId": "6eba43a0-bbfa-4c1e-f606-323a23712f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd /content/pythia\n",
        "\n",
        "!ls configs/vqa/textvqa/lorra.yml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pythia\n",
            "configs/vqa/textvqa/lorra.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LbRPnInsGTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pythia_path = '/content/pythia'\n",
        "lorra_model_config_path = '/content/pythia/configs/vqa/textvqa/lorra.yml'\n",
        "detectron_model_config_path = '/content/configs/detectron_model/detectron_model.yaml'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VjKAIedsGTh",
        "colab_type": "code",
        "outputId": "c258f3f1-4ae9-4413-858d-0bad763b2228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "%mkdir model_data\n",
        "\n",
        "!wget -O /content/model_data/vocabulary_100k.txt https://dl.fbaipublicfiles.com/pythia/data/vocabulary_100k.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2019-06-08 20:10:17--  https://dl.fbaipublicfiles.com/pythia/data/vocabulary_100k.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 626738 (612K) [text/plain]\n",
            "Saving to: ‘/content/model_data/vocabulary_100k.txt’\n",
            "\n",
            "/content/model_data 100%[===================>] 612.05K  1.72MB/s    in 0.3s    \n",
            "\n",
            "2019-06-08 20:10:18 (1.72 MB/s) - ‘/content/model_data/vocabulary_100k.txt’ saved [626738/626738]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iUf_fpFsGTo",
        "colab_type": "code",
        "outputId": "3103e2fe-a230-47f7-e8e1-fc0af938615e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1326
        }
      },
      "source": [
        "!wget -O /content/model_data/answers_vqa.txt https://dl.fbaipublicfiles.com/pythia/data/answers_vqa.txt\n",
        "!wget -O /content/model_data/vocabulary_100k.txt https://dl.fbaipublicfiles.com/pythia/data/vocabulary_100k.txt\n",
        "!wget -O /content/model_data/detectron_model.pth  https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.pth \n",
        "!wget -O /content/model_data/pythia.pth https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.pth\n",
        "!wget -O /content/model_data/pythia.yaml https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.yml\n",
        "!wget -O /content/model_data/detectron_model.yaml https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.yaml\n",
        "!wget -O /content/model_data/detectron_weights.tar.gz https://dl.fbaipublicfiles.com/pythia/data/detectron_weights.tar.gz\n",
        "!tar xf /content/model_data/detectron_weights.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-08 20:11:03--  https://dl.fbaipublicfiles.com/pythia/data/answers_vqa.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24768 (24K) [text/plain]\n",
            "Saving to: ‘/content/model_data/answers_vqa.txt’\n",
            "\n",
            "/content/model_data 100%[===================>]  24.19K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-06-08 20:11:03 (399 KB/s) - ‘/content/model_data/answers_vqa.txt’ saved [24768/24768]\n",
            "\n",
            "--2019-06-08 20:11:04--  https://dl.fbaipublicfiles.com/pythia/data/vocabulary_100k.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 626738 (612K) [text/plain]\n",
            "Saving to: ‘/content/model_data/vocabulary_100k.txt’\n",
            "\n",
            "/content/model_data 100%[===================>] 612.05K  1.53MB/s    in 0.4s    \n",
            "\n",
            "2019-06-08 20:11:05 (1.53 MB/s) - ‘/content/model_data/vocabulary_100k.txt’ saved [626738/626738]\n",
            "\n",
            "--2019-06-08 20:11:06--  https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 684079216 (652M) [application/octet-stream]\n",
            "Saving to: ‘/content/model_data/detectron_model.pth’\n",
            "\n",
            "/content/model_data 100%[===================>] 652.39M  28.2MB/s    in 24s     \n",
            "\n",
            "2019-06-08 20:11:31 (27.0 MB/s) - ‘/content/model_data/detectron_model.pth’ saved [684079216/684079216]\n",
            "\n",
            "--2019-06-08 20:11:32--  https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 713440524 (680M) [application/octet-stream]\n",
            "Saving to: ‘/content/model_data/pythia.pth’\n",
            "\n",
            "/content/model_data 100%[===================>] 680.39M  28.0MB/s    in 25s     \n",
            "\n",
            "2019-06-08 20:11:57 (27.0 MB/s) - ‘/content/model_data/pythia.pth’ saved [713440524/713440524]\n",
            "\n",
            "--2019-06-08 20:11:58--  https://dl.fbaipublicfiles.com/pythia/pretrained_models/vqa2/pythia_train_val.yml\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6577 (6.4K) [text/plain]\n",
            "Saving to: ‘/content/model_data/pythia.yaml’\n",
            "\n",
            "/content/model_data 100%[===================>]   6.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-08 20:11:58 (50.3 MB/s) - ‘/content/model_data/pythia.yaml’ saved [6577/6577]\n",
            "\n",
            "--2019-06-08 20:11:59--  https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.yaml\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 918 [text/plain]\n",
            "Saving to: ‘/content/model_data/detectron_model.yaml’\n",
            "\n",
            "/content/model_data 100%[===================>]     918  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-08 20:12:00 (11.7 MB/s) - ‘/content/model_data/detectron_model.yaml’ saved [918/918]\n",
            "\n",
            "--2019-06-08 20:12:01--  https://dl.fbaipublicfiles.com/pythia/data/detectron_weights.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15544345 (15M) [application/gzip]\n",
            "Saving to: ‘/content/model_data/detectron_weights.tar.gz’\n",
            "\n",
            "/content/model_data 100%[===================>]  14.82M  15.3MB/s    in 1.0s    \n",
            "\n",
            "2019-06-08 20:12:02 (15.3 MB/s) - ‘/content/model_data/detectron_weights.tar.gz’ saved [15544345/15544345]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfHdTsWruLyC",
        "colab_type": "code",
        "outputId": "d303fdb9-858c-4f44-8d24-652215c3d7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -O /content/model_data/answers_textvqa_more_than_1.txt  https://dl.fbaipublicfiles.com/pythia/data/answers_textvqa_more_than_1.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-08 20:13:46--  https://dl.fbaipublicfiles.com/pythia/data/answers_textvqa_more_than_1.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32540 (32K) [text/plain]\n",
            "Saving to: ‘/content/model_data/answers_textvqa_more_than_1.txt’\n",
            "\n",
            "/content/model_data 100%[===================>]  31.78K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-06-08 20:13:46 (441 KB/s) - ‘/content/model_data/answers_textvqa_more_than_1.txt’ saved [32540/32540]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkD2vqEuu8Rn",
        "colab_type": "code",
        "outputId": "b592a0eb-bd4c-4f0c-c29e-34d41b71439a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -O /content/model_data/lorra.pth https://dl.fbaipublicfiles.com/pythia/pretrained_models/textvqa/lorra_best.pth"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-08 20:18:03--  https://dl.fbaipublicfiles.com/pythia/pretrained_models/textvqa/lorra_best.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 892955500 (852M) [application/octet-stream]\n",
            "Saving to: ‘/content/model_data/lorra.pth’\n",
            "\n",
            "/content/model_data 100%[===================>] 851.59M  27.5MB/s    in 32s     \n",
            "\n",
            "2019-06-08 20:18:36 (26.7 MB/s) - ‘/content/model_data/lorra.pth’ saved [892955500/892955500]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks_2FC5WsGUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextVQADemo:\n",
        "    TARGET_IMAGE_SIZE = [448, 448]\n",
        "    CHANNEL_MEAN = [0.485, 0.456, 0.406]\n",
        "    CHANNEL_STD = [0.229, 0.224, 0.225]\n",
        "    \n",
        "    def __init__(self):\n",
        "        self._init_processors()\n",
        "        self.lorra_model = self._build_lorra_model()\n",
        "        self.detection_model = self._build_detection_model()\n",
        "        self.resnet_model = self._build_resnet_model()\n",
        "        \n",
        "    def _init_processors(self):\n",
        "        \"\"\"\n",
        "        Pythia uses processors is to keep data processing pipelines as similar as\n",
        "        possible for different datasets and allow code reusability.\n",
        "        \"\"\"\n",
        "        with open(\"pythia/configs/vqa/textvqa/lorra.yml\") as f:\n",
        "            config = yaml.load(f)\n",
        "            \n",
        "\n",
        "        #update config with includes for model specific config\n",
        "        for inc in config.get(\"includes\", []):\n",
        "            config.update(yaml.load(open(\"pythia/pythia/\"+ inc)))\n",
        "\n",
        "        config = ConfigNode(config)\n",
        "        config.datasets = 'textvqa'\n",
        "        config.training_parameters.evalai_inference = True\n",
        "        textvqa_config = config.task_attributes.vqa.dataset_attributes.textvqa\n",
        "        \n",
        "        answer_processor_config = textvqa_config.processors.answer_processor\n",
        "        answer_processor_config.params.vocab_file = \\\n",
        "            \"/content/model_data/answers_textvqa_more_than_1.txt\"\n",
        "        self.answer_processor = SoftCopyAnswerProcessor(answer_processor_config.params)\n",
        "        print(\"self.answer_processor.get_vocab_size()\", self.answer_processor.get_vocab_size())\n",
        "    \n",
        "        registry.register(\"textvqa_num_final_outputs\", \n",
        "                      self.answer_processor.get_vocab_size())\n",
        "        registry.register(\"textvqa_answer_processor\", self.answer_processor)\n",
        "        \n",
        "        text_processor_config = textvqa_config.processors.text_processor\n",
        "        text_processor_config.params.vocab.vocab_file = \"/content/model_data/vocabulary_100k.txt\"\n",
        "        self.text_processor = VocabProcessor(text_processor_config.params)\n",
        "        registry.register(\"textvqa_text_processor\", self.text_processor)\n",
        "        registry.register(\"textvqa_text_vocab_size\", \n",
        "                      self.text_processor.get_vocab_size())\n",
        "        \n",
        "        ocr_token_processor_config = textvqa_config.processors.ocr_token_processor\n",
        "        self.ocr_token_processor = SimpleWordProcessor(ocr_token_processor_config)\n",
        "        registry.register(\"textvqa_ocr_token_processor\", self.ocr_token_processor)\n",
        "        #pprint(text_processor_config)\n",
        "        \n",
        "        context_processor_config = textvqa_config.processors.context_processor\n",
        "        self.context_processor = FastTextProcessor(context_processor_config.params)\n",
        "        registry.register(\"textvqa_context_processor\", self.context_processor)\n",
        "        \n",
        "        self.config = config\n",
        "\n",
        "        registry.register(\"config\", config)\n",
        "        #pprint(config.classifier.keys())\n",
        "        \n",
        "        \n",
        "    def _add_imdb_details(self):\n",
        "        imdb_files = self.config.imdb_files\n",
        "        dataset_type = 'textvqa'\n",
        "        if dataset_type not in imdb_files:\n",
        "            raise ValueError(\n",
        "                \"Dataset type {} is not present in \"\n",
        "                \"imdb_files of dataset config\".format(dataset_type)\n",
        "            )\n",
        "\n",
        "        self.imdb_file = imdb_files[dataset_type][imdb_file_index]\n",
        "        self.imdb_file = self._get_absolute_path(self.imdb_file)\n",
        "        self.imdb = ImageDatabase(self.imdb_file)\n",
        "        \n",
        "    def _multi_gpu_state_to_single(self, state_dict):\n",
        "        new_sd = {}\n",
        "        for k, v in state_dict.items():\n",
        "            if not k.startswith('module.'):\n",
        "                raise TypeError(\"Not a multiple GPU state of dict\")\n",
        "            k1 = k[7:]\n",
        "            new_sd[k1] = v\n",
        "        return new_sd\n",
        "    \n",
        "\n",
        "    def _build_lorra_model(self):\n",
        "        state_dict = torch.load('/content/model_data/lorra.pth')\n",
        "        #pprint(state_dict)\n",
        "        model_config = self.config.model_attributes.lorra\n",
        "        pprint(self.config.datasets)\n",
        "        model = LoRRA(model_config)\n",
        "        model.build()\n",
        "        model.init_losses_and_metrics()\n",
        "        self.model = model\n",
        "        #print(model.params)\n",
        "        if list(state_dict.keys())[0].startswith('module') and \\\n",
        "           not hasattr(model, 'module'):\n",
        "            state_dict = self._multi_gpu_state_to_single(state_dict)\n",
        "        model.load_state_dict(state_dict)\n",
        "        model.to(\"cuda\")\n",
        "        model.eval()\n",
        "    \n",
        "        return model\n",
        "    \n",
        "    def _build_resnet_model(self):\n",
        "        self.data_transforms = transforms.Compose([\n",
        "            transforms.Resize(self.TARGET_IMAGE_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.CHANNEL_MEAN, self.CHANNEL_STD),\n",
        "        ])\n",
        "        resnet152 = models.resnet152(pretrained=True)\n",
        "        resnet152.eval()\n",
        "        modules = list(resnet152.children())[:-2]\n",
        "        self.resnet152_model = torch.nn.Sequential(*modules)\n",
        "        self.resnet152_model.to(\"cuda\")\n",
        "        \n",
        "    def _build_detection_model(self):\n",
        "        cfg.merge_from_file('/content/pythia/configs/detectron_model/detectron_model.yaml')\n",
        "        cfg.freeze()\n",
        "        model = build_detection_model(cfg)\n",
        "        checkpoint = torch.load('data/detectron/model/detectron_model.pth', \n",
        "                                  map_location=torch.device(\"cpu\"))\n",
        "        load_state_dict(model, checkpoint.pop(\"model\"))\n",
        "\n",
        "        model.to(\"cuda\")\n",
        "        model.eval()\n",
        "        return model\n",
        "    \n",
        "    \n",
        "    def add_ocr_details(self, sample_info, sample):\n",
        "        if self.use_ocr:\n",
        "            # Preprocess OCR tokens\n",
        "            ocr_tokens = [\n",
        "                self.ocr_token_processor({\"text\": token})[\"text\"]\n",
        "                for token in sample_info[\"ocr_tokens\"]\n",
        "            ]\n",
        "            # Get embeddings for tokens\n",
        "            context = self.context_processor({\"tokens\": ocr_tokens})\n",
        "            sample.context = context[\"text\"]\n",
        "            sample.context_tokens = context[\"tokens\"]\n",
        "            sample.context_feature_0 = context[\"text\"]\n",
        "            sample.context_info_0 = Sample()\n",
        "            sample.context_info_0.max_features = context[\"length\"]\n",
        "\n",
        "            order_vectors = torch.eye(len(sample.context_tokens))\n",
        "            order_vectors[context[\"length\"] :] = 0\n",
        "            sample.order_vectors = order_vectors\n",
        "\n",
        "        if self.use_ocr_info and \"ocr_info\" in sample_info:\n",
        "            sample.ocr_bbox = self.bbox_processor({\"info\": sample_info[\"ocr_info\"]})[\n",
        "                \"bbox\"\n",
        "            ]\n",
        "\n",
        "        return sample\n",
        "    \n",
        "    def predict(self, url, question):\n",
        "        with torch.no_grad():\n",
        "            detectron_features = self.get_detectron_features(url)\n",
        "            resnet_features = self.get_resnet_features(url)\n",
        "        \n",
        "            sample = Sample()\n",
        "\n",
        "            processed_text = self.text_processor({\"text\": question})\n",
        "            sample.text = processed_text[\"text\"]\n",
        "            sample.text_len = len(processed_text[\"tokens\"])\n",
        "\n",
        "            sample.image_feature_0 = detectron_features\n",
        "            sample.image_info_0 = Sample({\n",
        "              \"max_features\": torch.tensor(100, dtype=torch.long)\n",
        "            })\n",
        "            \n",
        "            \n",
        "            # Get embeddings for tokens\n",
        "            context = self.context_processor({\"tokens\": processed_text[\"tokens\"]})\n",
        "            sample.context = context[\"text\"]\n",
        "            sample.context_tokens = context[\"tokens\"]\n",
        "            sample.context_feature_0 = context[\"text\"]\n",
        "            sample.context_info_0 = Sample()\n",
        "            sample.context_info_0.max_features = context[\"length\"]\n",
        "\n",
        "            order_vectors = torch.eye(len(sample.context_tokens))\n",
        "            order_vectors[context[\"length\"] :] = 0\n",
        "            sample.order_vectors = order_vectors\n",
        "\n",
        "            sample.image_feature_1 = resnet_features\n",
        "\n",
        "            sample_list = SampleList([sample])\n",
        "            sample_list = sample_list.to(\"cuda\")\n",
        "\n",
        "            scores = self.lorra_model(sample_list)[\"scores\"]\n",
        "            scores = torch.nn.functional.softmax(scores, dim=1)\n",
        "            actual, indices = scores.topk(5, dim=1)\n",
        "\n",
        "            top_indices = indices[0]\n",
        "            top_scores = actual[0]\n",
        "\n",
        "            probs = []\n",
        "            answers = []\n",
        "\n",
        "            for idx, score in enumerate(top_scores):\n",
        "                probs.append(score.item())\n",
        "                answers.append(\n",
        "                    self.answer_processor.idx2word(top_indices[idx].item())\n",
        "                )\n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        return probs, answers\n",
        "    \n",
        "    def get_actual_image(self, image_path):\n",
        "        if image_path.startswith('http'):\n",
        "            path = requests.get(image_path, stream=True).raw\n",
        "        else:\n",
        "            path = image_path\n",
        "        return path\n",
        "\n",
        "    def _image_transform(self, image_path):\n",
        "        path = self.get_actual_image(image_path)\n",
        "\n",
        "        img = Image.open(path)\n",
        "        im = np.array(img).astype(np.float32)\n",
        "        im = im[:, :, ::-1]\n",
        "        im -= np.array([102.9801, 115.9465, 122.7717])\n",
        "        im_shape = im.shape\n",
        "        im_size_min = np.min(im_shape[0:2])\n",
        "        im_size_max = np.max(im_shape[0:2])\n",
        "        im_scale = float(800) / float(im_size_min)\n",
        "        # Prevent the biggest axis from being more than max_size\n",
        "        if np.round(im_scale * im_size_max) > 1333:\n",
        "            im_scale = float(1333) / float(im_size_max)\n",
        "        im = cv2.resize(\n",
        "           im,\n",
        "           None,\n",
        "           None,\n",
        "           fx=im_scale,\n",
        "           fy=im_scale,\n",
        "           interpolation=cv2.INTER_LINEAR\n",
        "           )\n",
        "        img = torch.from_numpy(im).permute(2, 0, 1)\n",
        "        return img, im_scale\n",
        "    \n",
        "    def _process_feature_extraction(self, output,\n",
        "                                    im_scales,\n",
        "                                    feat_name='fc6',\n",
        "                                    conf_thresh=0.2):\n",
        "        batch_size = len(output[0][\"proposals\"])\n",
        "        n_boxes_per_image = [len(_) for _ in output[0][\"proposals\"]]\n",
        "        score_list = output[0][\"scores\"].split(n_boxes_per_image)\n",
        "        score_list = [torch.nn.functional.softmax(x, -1) for x in score_list]\n",
        "        feats = output[0][feat_name].split(n_boxes_per_image)\n",
        "        cur_device = score_list[0].device\n",
        "\n",
        "        feat_list = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            dets = output[0][\"proposals\"][i].bbox / im_scales[i]\n",
        "            scores = score_list[i]\n",
        "\n",
        "            max_conf = torch.zeros((scores.shape[0])).to(cur_device)\n",
        "\n",
        "            for cls_ind in range(1, scores.shape[1]):\n",
        "                cls_scores = scores[:, cls_ind]\n",
        "                keep = nms(dets, cls_scores, 0.5)\n",
        "                max_conf[keep] = torch.where(cls_scores[keep] > max_conf[keep],\n",
        "                                            cls_scores[keep],\n",
        "                                            max_conf[keep])\n",
        "\n",
        "            keep_boxes = torch.argsort(max_conf, descending=True)[:100]\n",
        "            feat_list.append(feats[i][keep_boxes])\n",
        "        return feat_list\n",
        "\n",
        "    def masked_unk_softmax(self, x, dim, mask_idx):\n",
        "        x1 = F.softmax(x, dim=dim)\n",
        "        x1[:, mask_idx] = 0\n",
        "        x1_sum = torch.sum(x1, dim=1, keepdim=True)\n",
        "        y = x1 / x1_sum\n",
        "        return y\n",
        "\n",
        "    def get_resnet_features(self, image_path):\n",
        "        path = self.get_actual_image(image_path)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img_transform = self.data_transforms(img)\n",
        "        \n",
        "        if img_transform.shape[0] == 1:\n",
        "            img_transform = img_transform.expand(3, -1, -1)\n",
        "        img_transform = img_transform.unsqueeze(0).to(\"cuda\")\n",
        "        \n",
        "        features = self.resnet152_model(img_transform).permute(0, 2, 3, 1)\n",
        "        features = features.view(196, 2048)\n",
        "        return features\n",
        "\n",
        "    def get_detectron_features(self, image_path):\n",
        "        im, im_scale = self._image_transform(image_path)\n",
        "        img_tensor, im_scales = [im], [im_scale]\n",
        "        current_img_list = to_image_list(img_tensor, size_divisible=32)\n",
        "        current_img_list = current_img_list.to('cuda')\n",
        "        with torch.no_grad():\n",
        "            output = self.detection_model(current_img_list)\n",
        "        feat_list = self._process_feature_extraction(output, im_scales, \n",
        "                                                    'fc6', 0.2)\n",
        "        return feat_list[0]\n",
        "      \n",
        "    def get_ocr_tokens(self, image_path):\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCS-jJhpwzfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W7-pwjzsGVW",
        "colab_type": "code",
        "outputId": "118bed43-e790-43c3-f89d-ba14d8c2c00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "demo = TextVQADemo()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pythia/pythia/tasks/processors.py:690: UserWarning: 'max_length' not defined in the config. Setting to default of 50\n",
            "  \"Setting to default of {}\".format(self.DEFAULT_MAX_LENGTH)\n",
            "\r/content/pythia/pythia/.vector_cache/glove.6B.zip: 0.00B [00:00, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.answer_processor.get_vocab_size() 4047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/pythia/pythia/.vector_cache/glove.6B.zip: 862MB [00:53, 16.2MB/s]                           \n",
            "100%|█████████▉| 399916/400000 [00:44<00:00, 8900.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-94b20dfc1e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextVQADemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-ebc3ce9cb10a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_processors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlorra_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_lorra_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_detection_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_resnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-ebc3ce9cb10a>\u001b[0m in \u001b[0;36m_build_lorra_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_lorra_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model_data/lorra_best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;31m#pprint(state_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_attributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlorra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/model_data/lorra_best.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugFgBDuSsGVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_widgets(url, question):\n",
        "    image_text = widgets.Text(\n",
        "        description=\"Image URL\", layout=Layout(minwidth=\"70%\")\n",
        "    )\n",
        "    question_text = widgets.Text(\n",
        "        description=\"Question\", layout=Layout(minwidth=\"70%\")\n",
        "    )\n",
        "\n",
        "    image_text.value = url\n",
        "    question_text.value = question\n",
        "    submit_button = widgets.Button(description=\"Ask TextVQA!\")\n",
        "\n",
        "    display(image_text)\n",
        "    display(question_text)\n",
        "    display(submit_button)\n",
        "\n",
        "    submit_button.on_click(lambda b: on_button_click(\n",
        "      b, image_text, question_text\n",
        "    ))\n",
        "\n",
        "    return image_text, question_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA5zx6GDsGV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_button_click(b, image_text, question_text):\n",
        "    clear_output()\n",
        "    image_path = demo.get_actual_image(image_text.value)\n",
        "    image = Image.open(image_path)\n",
        "  \n",
        "    scores, predictions = demo.predict(image_text.value, question_text.value)\n",
        "    scores = [score * 100 for score in scores]\n",
        "    df = pd.DataFrame({\n",
        "      \"Prediction\": predictions,\n",
        "      \"Confidence\": scores\n",
        "    })\n",
        "  \n",
        "    init_widgets(image_text.value, question_text.value)\n",
        "    display(image)\n",
        "\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSvoBoWFsGWB",
        "colab_type": "code",
        "outputId": "4d5491f4-4152-4f9d-ac83-31347abff1a2",
        "colab": {}
      },
      "source": [
        "image_text, question_text = init_widgets(\n",
        "    \"http://images.cocodataset.org/train2017/000000505539.jpg\", \n",
        "    \"where is this place?\"\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c4b45e343658>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     submit_button.on_click(lambda b: on_button_click(\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     ))\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-346287182691>\u001b[0m in \u001b[0;36mon_button_click\u001b[0;34m(b, image_text, question_text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     df = pd.DataFrame({\n",
            "\u001b[0;32m<ipython-input-3-c6b1d1dcb3f2>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, url, question)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 answers.append(\n\u001b[0;32m--> 202\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 )\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/pythia/pythia/tasks/processors.py\u001b[0m in \u001b[0;36midx2word\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_answers_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/pythia/pythia/utils/text_utils.py\u001b[0m in \u001b[0;36midx2word\u001b[0;34m(self, n_w)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0midx2word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_unk_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bk9YYszsGWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}